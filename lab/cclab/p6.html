<!DOCTYPE html>
<html lang="en">
  <head>
    <title>The Questioning Camera | Salil Parekh</title>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <!-- import the webpage's stylesheet -->
    <link rel="stylesheet" href="style.css" />

    <!-- import the webpage's javascript file -->

  </head>

  <body>
    <!-- navigation menu -->
    <div class="nav">
      <h1><a href="index.html">Salil Parekh</a></h1>
      <ul class="nav-link">
        <li><a href="p1.html">Nixon Watch</a></li>
        <li><a href="p2.html">Coffee Cup Generator</a></li>
        <li><a href="p3.html">The Context Clock</a></li>
        <li><a href="p4.html">The Performance</a></li>
        <li><a href="p5.html">Pixelcryption</a></li>
        <li><a href="p6.html">The Questioning Camera</a></li>
        <li><a href="p7.html">Museum of Salil</a></li>
        <li><a href="p8.html">Consentful Interface</a></li>
        <li><a href="p9.html">My Door</a></li>
        <li><a href="p10.html">Sky Globe</a></li>
      </ul>
      <a href="about.html">About</a>
    </div>

    <!--   main content -->
    <div class="content">
      <h1>The Questioning Camera</h1>
      <p>
        The camera is a wonderful tool. An artificial eye, but capable of so
        much unlike ours. It is capable of sensing so much more than what it
        merely 'sees'. Those who control a camera have an extra pair of sensory
        organs, which are highly capable, like a superpower. A CCTV camera is
        used to surveill and spy, but a regular digital camera is used to
        document moments in one's life. The same tool can be used for a wide
        range of purposes, some benign, and others with a malicious intent. A
        camera can 'see' much more than we can, technically and metaphorically.
        Cameras can see across the electromagnetic spectrum and beyond, which is
        highly functional. Some also incorporate small levels of intelligence,
        which can be used to detect intruders, calculate distance, or recognise
        certain entities. Even small amounts of intelligence can make a camera a
        very powerful tool or weapon.
      </p>
      <p>
        A neutral camera with no intelligence has a lot of potential. Although
        it can be used to augment our senses to see what we can't with our own
        eyes, it can also help augment our intelligence. Cameras can be trained
        to perceive things differently from how we see the world. They can help
        us think differently and open our minds. A challenge I face regularly is
        my acceptance of the world around me. I don't often questions the things
        I see around me, and accept what I see at face value. This has perhaps
        happened over time. I've stopped questioning the entities and systems in
        my environment. I wish I could regain that curiosity I once had. The
        need to not only question everything I see, but the need to fully
        understand how everything around me works.
      </p>
      <p>
        What better tool than a camera to help me out with this?
      </p>
      <h2>
        Questioning Camera
      </h2>
      <br />

      <div class="bSketch">
        <iframe
          width="600px"
          height="600px"
          allow="camera"
          src="https://editor.p5js.org/burnedsap/embed/5u3FL0Zbf"
        ></iframe>
        <small>
          <i>Questioning Camera (Give it a few minutes to load!)  </i
          ><a
            href="https://editor.p5js.org/burnedsap/sketches/5u3FL0Zbf"
            target="_blank"
            >See the code â†’</a
          ></small
        >
      </div>
      <p>
        I created the <b>Questioning Camera</b> to augment how I view the world
        around me. It's a helpful tool which reminds me to ask questions and
        think a little more. With the help of a simple machine learning
        algorithm, it recognises the entities it sees, and accordingly frames
        questions for me-the user. It uses the COCO-SSD Object Detection model
        adpated to ml5.js to detect objects. The COCO-SSD model classifies
        objects into 90 different classifications. Although it is not
        exhaustive, it does detect objects accurately and quickly. Once it
        identifies an object it recognises, it draws a rectangle around it
        calling it out, and overlays a few questions for the viewer to think
        about. The intent is to help the viewer think critically about what they
        see. It tries to redefine the way in which we accept our environment.
      </p>
      <div class="image-three-grid">
        <img
          src="glitch-assets/Questioning-Camera (12).png"
          alt="questioning-camera"
          width="100%"
        />
        <img
          src="glitch-assets/Questioning-Camera (8).png"
          alt="questioning-camera"
          width="100%"
        />
        <img
          src="glitch-assets/Questioning-Camera (9).png"
          alt="questioning-camera"
          width="100%"
        />
      </div>
      <div class="image-three-grid">
        <img
          src="glitch-assets/Questioning-Camera (5).png"
          alt="questioning-camera"
          width="100%"
        />
        <img
          src="glitch-assets/Questioning-Camera (6).png"
          alt="questioning-camera"
          width="100%"
        />
        <img
          src="glitch-assets/Questioning-Camera (10).png"
          alt="questioning-camera"
          width="100%"
        />
      </div>
      <small><i>Some images taken with the questioning camera. </i></small>

      <h2>
        Design Process
      </h2>
      <div class="image-two-grid">
        
          <img
            src="glitch-assets/2020_10_19 13_17 Office Lens (1).jpg"
            alt="sketches"
            width="100%"
          />
        <img
            src="glitch-assets/2020_10_19 13_17 Office Lens (2).jpg"
            alt="sketches"
            width="100%"
          />
          
        </div>
      
      <small
            ><i>
              Initial ideation sketches 
              </i
            ></small
          >
      <p>
        From the first batch of ideas, I downselected 3 ideas. Two of those
        ideas were quite similar, both about small amounts of local
        intelligence, which I was particularly interested in. The idea of a
        small, local intelligence is particularly fascinating to me as it is
        diametrically opposite of the idea of an all-known 'AI' which is quite
        popular. We are very far away from the idea of a general purpose
        intelligence, and so I feel a lot of the hype and attention towards the
        idea of an AI is unjustified. However, we can create entities with small
        amounts of local intelligence, which is what most objects marketed as
        'AI' powered really are.
      </p>

      <p>
        To create a camera which could not only understand what it sees but also
        formulate relevant questions, I had to give it some intelligence. I
        created a simple camera sketch, which could read the video feed from the
        webcam. I then integrated the
        <a
          href="https://ml5js.org/reference/api-ObjectDetector/"
          target="_blank"
          >ml5js Object Detector</a
        >
        model within the sketch. I picked the COCO-SSD version of the model
        since it had a defined set of objects it could identify. This would help
        me assign specific questions for every kind of object.
      </p>
      <p>
        The sketch worked as planned, and could identify objects. However since
        the machine learning model was infering each frame, it ran very slowly
        (~1-3fps). This was not only unpleasant to look at, but it was slow as
        well. To make the user experience smoother, I changed the configuration
        of the sketch, so that the machine learning model would only start
        infering once the user has taken a photo. Hence, the inference would run
        once, making it much faster. I added 3 buttons, a <b>shutter button</b>,
        <b>clear button</b>, and a <b>download button</b>. The shutter button is
        used to take a picture and start the machine learning model. The clear
        button switch the camera back to the viewfinder mode, ready to take a
        picture again. The download button allows the user to download the image
        if they wish to.
      </p>
      <p>
        I recreated the object classification from the COCO-SSD documentation to
        assign custom questions to each kind of object. To simplify the process
        of assigning the correct questions, I used an object and a nifty little
        logic which used a word matching to avoid using a series of complex and
        long if/else loops.
      </p>
      <p>
        I also tried to visually differentiate the detected object from the
        background using <code>PGraphics</code> masking and
        <code>filter(INVERT)</code>, but it didn't work out as planned. Masking
        a PGraphic with another PGraphic is a little more complex than masking
        an image.
      </p>
      <p>
        To make it easier to shoot with when out and about, I created a
        <a href="http://questioning-camera.glitch.me" target="_blank"
          >mobile version</a
        >
        of the sketch, with a slightly different interface. This required a
        slightly different code to access the rear camera of the smartphone, but
        it works just as well as it does on a desktop.
      </p>
      <h2>
        Reflection
      </h2>
      <p>
        In the process of creating an experimental camera, I've ended up
        creating a lens through which I can look at the world. Giving it a small
        amount of local intelligence augments my own intelligence and gives me
        additional capabilities. Visual perception is difficult, and
        computationally heavy! Even with a low-res camera like the ones used on
        webcams, it can be quite challenging to read and analyse the incoming
        data. It also helped me realise the challenges of inference through
        pixels. A digital camera only understands pixels, and can't see or
        perceive anything. We have to add multiple layers of intelligence in
        order to give it the capability to actually see and comprehend.
      </p>
    </div>
  </body>
</html>
